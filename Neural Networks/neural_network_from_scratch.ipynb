{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1520fa8-abb7-4ca6-928e-b61abea19d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb02ab65-2885-431c-8147-9eb07b21b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and biases\n",
    "def initialize_parameters(n_input, n_hidden, n_output):\n",
    "    np.random.seed(42)  # for reproducibility\n",
    "    weights_input_hidden = np.random.rand(n_input, n_hidden) - 0.5\n",
    "    weights_hidden_output = np.random.rand(n_hidden, n_output) - 0.5\n",
    "    bias_hidden = np.random.rand(n_hidden) - 0.5\n",
    "    bias_output = np.random.rand(n_output) - 0.5\n",
    "    \n",
    "    return weights_input_hidden, weights_hidden_output, bias_hidden, bias_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80245d4b-6d3e-420a-9562-64f059dbfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output):\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "    \n",
    "    return hidden_layer_output, output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2ed9ca-fed8-4b8d-9f19-2b6ad3962bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, hidden_layer_output, output_layer_output, weights_hidden_output):\n",
    "    output_error = y - output_layer_output\n",
    "    output_delta = output_error * sigmoid_derivative(output_layer_output)\n",
    "    \n",
    "    hidden_error = output_delta.dot(weights_hidden_output.T)\n",
    "    hidden_delta = hidden_error * sigmoid_derivative(hidden_layer_output)\n",
    "    \n",
    "    return hidden_delta, output_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b580d99-2663-4b9e-890f-899f8661ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(X, hidden_layer_output, hidden_delta, output_delta, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output, learning_rate):\n",
    "    weights_hidden_output += hidden_layer_output.T.dot(output_delta) * learning_rate\n",
    "    bias_output += np.sum(output_delta, axis=0) * learning_rate\n",
    "    \n",
    "    weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n",
    "    bias_hidden += np.sum(hidden_delta, axis=0) * learning_rate\n",
    "    \n",
    "    return weights_input_hidden, weights_hidden_output, bias_hidden, bias_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48af66a2-d5f6-432d-9a27-87899705a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X, y, n_hidden, epochs, learning_rate):\n",
    "    n_input = X.shape[1]\n",
    "    n_output = y.shape[1]\n",
    "    \n",
    "    weights_input_hidden, weights_hidden_output, bias_hidden, bias_output = initialize_parameters(n_input, n_hidden, n_output)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        hidden_layer_output, output_layer_output = forward_propagation(X, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output)\n",
    "        \n",
    "        hidden_delta, output_delta = backward_propagation(X, y, hidden_layer_output, output_layer_output, weights_hidden_output)\n",
    "        \n",
    "        weights_input_hidden, weights_hidden_output, bias_hidden, bias_output = update_parameters(X, hidden_layer_output, hidden_delta, output_delta, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output, learning_rate)\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            loss = np.mean(np.square(y - output_layer_output))\n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss}')\n",
    "    \n",
    "    return weights_input_hidden, weights_hidden_output, bias_hidden, bias_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b4a03a-cd77-41f1-b885-cfc5082c5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output):\n",
    "    _, output_layer_output = forward_propagation(X, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output)\n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe2cb33-d51a-4e4f-b4b4-7282923947a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.25007000358505077\n",
      "Epoch 200, Loss: 0.2500622071298195\n",
      "Epoch 300, Loss: 0.2500562804933485\n",
      "Epoch 400, Loss: 0.2500507681456985\n",
      "Epoch 500, Loss: 0.2500456191968908\n",
      "Epoch 600, Loss: 0.2500407895115408\n",
      "Epoch 700, Loss: 0.2500362403021377\n",
      "Epoch 800, Loss: 0.25003193729995205\n",
      "Epoch 900, Loss: 0.25002785006345657\n",
      "Epoch 1000, Loss: 0.25002395139823846\n",
      "Epoch 1100, Loss: 0.2500202168676361\n",
      "Epoch 1200, Loss: 0.25001662437742583\n",
      "Epoch 1300, Loss: 0.25001315382109807\n",
      "Epoch 1400, Loss: 0.2500097867747854\n",
      "Epoch 1500, Loss: 0.2500065062329043\n",
      "Epoch 1600, Loss: 0.2500032963771507\n",
      "Epoch 1700, Loss: 0.2500001423727445\n",
      "Epoch 1800, Loss: 0.24999703018681235\n",
      "Epoch 1900, Loss: 0.24999394642458592\n",
      "Epoch 2000, Loss: 0.2499908781797143\n",
      "Epoch 2100, Loss: 0.24998781289547417\n",
      "Epoch 2200, Loss: 0.24998473823403575\n",
      "Epoch 2300, Loss: 0.24998164195121855\n",
      "Epoch 2400, Loss: 0.24997851177437094\n",
      "Epoch 2500, Loss: 0.24997533528113314\n",
      "Epoch 2600, Loss: 0.24997209977690124\n",
      "Epoch 2700, Loss: 0.24996879216881296\n",
      "Epoch 2800, Loss: 0.24996539883400964\n",
      "Epoch 2900, Loss: 0.2499619054798093\n",
      "Epoch 3000, Loss: 0.2499582969932337\n",
      "Epoch 3100, Loss: 0.2499545572770724\n",
      "Epoch 3200, Loss: 0.24995066906932403\n",
      "Epoch 3300, Loss: 0.24994661374241992\n",
      "Epoch 3400, Loss: 0.24994237107808903\n",
      "Epoch 3500, Loss: 0.2499379190130463\n",
      "Epoch 3600, Loss: 0.24993323334985515\n",
      "Epoch 3700, Loss: 0.24992828742628398\n",
      "Epoch 3800, Loss: 0.24992305173522394\n",
      "Epoch 3900, Loss: 0.24991749348567907\n",
      "Epoch 4000, Loss: 0.24991157609343778\n",
      "Epoch 4100, Loss: 0.2499052585876813\n",
      "Epoch 4200, Loss: 0.24989849491687563\n",
      "Epoch 4300, Loss: 0.24989123313368716\n",
      "Epoch 4400, Loss: 0.24988341443417386\n",
      "Epoch 4500, Loss: 0.24987497202090253\n",
      "Epoch 4600, Loss: 0.24986582975262467\n",
      "Epoch 4700, Loss: 0.24985590053432064\n",
      "Epoch 4800, Loss: 0.2498450843902903\n",
      "Epoch 4900, Loss: 0.24983326614886034\n",
      "Epoch 5000, Loss: 0.24982031264934998\n",
      "Epoch 5100, Loss: 0.24980606935903552\n",
      "Epoch 5200, Loss: 0.24979035625851864\n",
      "Epoch 5300, Loss: 0.24977296281615788\n",
      "Epoch 5400, Loss: 0.24975364182348753\n",
      "Epoch 5500, Loss: 0.24973210180039282\n",
      "Epoch 5600, Loss: 0.24970799759669016\n",
      "Epoch 5700, Loss: 0.24968091870964987\n",
      "Epoch 5800, Loss: 0.24965037469690654\n",
      "Epoch 5900, Loss: 0.24961577688057882\n",
      "Epoch 6000, Loss: 0.2495764152973781\n",
      "Epoch 6100, Loss: 0.2495314295329101\n",
      "Epoch 6200, Loss: 0.24947977166291754\n",
      "Epoch 6300, Loss: 0.249420158980374\n",
      "Epoch 6400, Loss: 0.24935101347897218\n",
      "Epoch 6500, Loss: 0.2492703841485887\n",
      "Epoch 6600, Loss: 0.2491758469722251\n",
      "Epoch 6700, Loss: 0.24906437605865617\n",
      "Epoch 6800, Loss: 0.24893217758855496\n",
      "Epoch 6900, Loss: 0.24877447624685928\n",
      "Epoch 7000, Loss: 0.2485852417501733\n",
      "Epoch 7100, Loss: 0.24835684140912334\n",
      "Epoch 7200, Loss: 0.248079604324766\n",
      "Epoch 7300, Loss: 0.247741285555388\n",
      "Epoch 7400, Loss: 0.2473264274614701\n",
      "Epoch 7500, Loss: 0.24681563541332888\n",
      "Epoch 7600, Loss: 0.24618482353848875\n",
      "Epoch 7700, Loss: 0.24540455286381155\n",
      "Epoch 7800, Loss: 0.24443968864849486\n",
      "Epoch 7900, Loss: 0.24324974802080399\n",
      "Epoch 8000, Loss: 0.2417904713116764\n",
      "Epoch 8100, Loss: 0.24001725670311305\n",
      "Epoch 8200, Loss: 0.237890992792841\n",
      "Epoch 8300, Loss: 0.23538628488554914\n",
      "Epoch 8400, Loss: 0.2325009476988532\n",
      "Epoch 8500, Loss: 0.22926415549231272\n",
      "Epoch 8600, Loss: 0.22573966309631743\n",
      "Epoch 8700, Loss: 0.22202123232223409\n",
      "Epoch 8800, Loss: 0.21822022880969366\n",
      "Epoch 8900, Loss: 0.2144489394161585\n",
      "Epoch 9000, Loss: 0.21080507631814174\n",
      "Epoch 9100, Loss: 0.20736186671517037\n",
      "Epoch 9200, Loss: 0.20416509787577178\n",
      "Epoch 9300, Loss: 0.20123568341143508\n",
      "Epoch 9400, Loss: 0.19857510609679513\n",
      "Epoch 9500, Loss: 0.19617137104522356\n",
      "Epoch 9600, Loss: 0.19400402824863255\n",
      "Epoch 9700, Loss: 0.19204768342125597\n",
      "Epoch 9800, Loss: 0.19027392474933566\n",
      "Epoch 9900, Loss: 0.18865176184332733\n",
      "Epoch 10000, Loss: 0.187146607774391\n",
      "Predictions:\n",
      "[[0.37539432]\n",
      " [0.81430879]\n",
      " [0.33454248]\n",
      " [0.36096015]]\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "# Hyperparameters\n",
    "n_hidden = 2\n",
    "epochs = 10000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Train the neural network\n",
    "weights_input_hidden, weights_hidden_output, bias_hidden, bias_output = train_neural_network(X, y, n_hidden, epochs, learning_rate)\n",
    "\n",
    "# Test the neural network\n",
    "predictions = predict(X, weights_input_hidden, weights_hidden_output, bias_hidden, bias_output)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a322a8b-bdd3-4fd7-953a-35c6bef482df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
