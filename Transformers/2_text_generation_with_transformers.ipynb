{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AWLOyvQq_w-E"
      },
      "outputs": [],
      "source": [
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # We can choose a different version like \"gpt2-medium\", \"gpt2-large\", etc.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = TFGPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TMCHn6hzvnD",
        "outputId": "dec7f08c-fc5a-4dd6-c232-3c1ed3c8aa72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt\n",
        "prompt = \"In a distant future, humanity has discovered\""
      ],
      "metadata": {
        "id": "Wl1lWMsxz0o0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the prompt text into input tokens and generate the attention mask\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
        "attention_mask = tf.ones_like(input_ids)  # Creates a mask filled with ones, as all input tokens are valid"
      ],
      "metadata": {
        "id": "bcc_myDTz3AJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text continuation with the attention mask and explicit pad token id\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=100,  # We can adjust this value to generate longer or shorter text\n",
        "    num_return_sequences=1,  # Number of different sequences to generate\n",
        "    no_repeat_ngram_size=2,  # Avoid repeating n-grams\n",
        "    top_k=50,  # Consider the top_k tokens by probability\n",
        "    top_p=0.95,  # Consider the cumulative probability of top_p tokens\n",
        "    temperature=0.7,  # Lower values make the output more focused and deterministic\n",
        "    do_sample=True,  # Use sampling to introduce randomness\n",
        "    attention_mask=attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id  # Explicitly set pad token id to eos token id\n",
        ")"
      ],
      "metadata": {
        "id": "gUf7_6Bcz6e2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the generated tokens back into text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "v8h5v-Tbz-e9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated story\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nHdXWW7_6KA",
        "outputId": "72728add-6806-4ede-d228-fa2e46c3bb91"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a distant future, humanity has discovered a way to make the world more like our own.\n",
            "\n",
            "The story of the U.S. military in World War II is one of heroism, triumph, and triumph. The story is about the American military's first ever use of a machine gun in a war, as well as the story's true story. In a time when America was facing a formidable enemy, it was necessary to be vigilant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4I0TD2lp1KwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}